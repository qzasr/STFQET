time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=12, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 1,419,136
**** training model ****
2025-08-28 16:03:14 | epoch: 0001/100, training time: 92.0s, inference time: 2.4s
train loss: 2.7897, val_loss: 2.1830
val loss decrease from inf to 2.1830, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 16:04:47 | epoch: 0002/100, training time: 91.4s, inference time: 2.5s
train loss: 2.4858, val_loss: 2.1239
val loss decrease from 2.1830 to 2.1239, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 16:06:22 | epoch: 0003/100, training time: 92.7s, inference time: 2.4s
train loss: 2.4290, val_loss: 2.0788
val loss decrease from 2.1239 to 2.0788, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 16:07:56 | epoch: 0004/100, training time: 90.7s, inference time: 2.4s
train loss: 2.3960, val_loss: 2.0860
2025-08-28 16:09:28 | epoch: 0005/100, training time: 90.1s, inference time: 2.4s
train loss: 2.3446, val_loss: 2.0811
2025-08-28 16:11:03 | epoch: 0006/100, training time: 93.0s, inference time: 2.4s
train loss: 2.3300, val_loss: 2.0567
val loss decrease from 2.0788 to 2.0567, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 16:12:32 | epoch: 0007/100, training time: 86.1s, inference time: 2.4s
train loss: 2.3247, val_loss: 2.0689
2025-08-28 16:14:02 | epoch: 0008/100, training time: 87.9s, inference time: 2.4s
train loss: 2.2985, val_loss: 2.0556
val loss decrease from 2.0567 to 2.0556, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 16:15:35 | epoch: 0009/100, training time: 90.4s, inference time: 2.4s
train loss: 2.2763, val_loss: 2.0698
2025-08-28 16:17:09 | epoch: 0010/100, training time: 91.8s, inference time: 2.4s
train loss: 2.3180, val_loss: 2.0742
2025-08-28 16:18:41 | epoch: 0011/100, training time: 89.3s, inference time: 2.4s
train loss: 2.2636, val_loss: 2.0645
2025-08-28 16:20:12 | epoch: 0012/100, training time: 89.0s, inference time: 2.4s
train loss: 2.2983, val_loss: 2.0727
2025-08-28 16:21:47 | epoch: 0013/100, training time: 91.7s, inference time: 2.4s
train loss: 2.2491, val_loss: 2.0447
val loss decrease from 2.0556 to 2.0447, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 16:23:19 | epoch: 0014/100, training time: 90.1s, inference time: 2.5s
train loss: 2.2644, val_loss: 2.0406
val loss decrease from 2.0447 to 2.0406, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 16:24:50 | epoch: 0015/100, training time: 88.5s, inference time: 2.5s
train loss: 2.2674, val_loss: 2.0754
2025-08-28 16:26:23 | epoch: 0016/100, training time: 90.7s, inference time: 2.4s
train loss: 2.2167, val_loss: 2.0919
2025-08-28 16:27:54 | epoch: 0017/100, training time: 88.1s, inference time: 2.4s
train loss: 2.2579, val_loss: 2.0547
2025-08-28 16:29:26 | epoch: 0018/100, training time: 89.4s, inference time: 2.4s
train loss: 2.2506, val_loss: 2.0780
2025-08-28 16:30:57 | epoch: 0019/100, training time: 88.5s, inference time: 2.4s
train loss: 2.2091, val_loss: 2.0555
2025-08-28 16:32:30 | epoch: 0020/100, training time: 90.9s, inference time: 2.4s
train loss: 2.1991, val_loss: 2.0597
2025-08-28 16:34:06 | epoch: 0021/100, training time: 93.5s, inference time: 2.5s
train loss: 2.1940, val_loss: 2.0531
2025-08-28 16:35:39 | epoch: 0022/100, training time: 91.4s, inference time: 2.4s
train loss: 2.1952, val_loss: 2.0798
early stop at epoch: 0022
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.8051, RMSE: 2.7836, MAPE: 6.06%
performance in each prediction step (train)
step 1: MAE=1.5365, RMSE=2.3086, MAPE=5.16%
step 2: MAE=1.8204, RMSE=2.8005, MAPE=6.10%
step 3: MAE=1.8343, RMSE=2.8356, MAPE=6.15%
step 4: MAE=1.8313, RMSE=2.8348, MAPE=6.15%
step 5: MAE=1.8350, RMSE=2.8401, MAPE=6.16%
step 6: MAE=1.8429, RMSE=2.8555, MAPE=6.20%
step 7: MAE=1.8540, RMSE=2.8759, MAPE=6.24%
step 8: MAE=1.8860, RMSE=2.9175, MAPE=6.35%
average: MAE=1.8051, RMSE=2.7836, MAPE=6.06%
val MAE: 2.0798, RMSE: 3.1607, MAPE: 7.02%
performance in each prediction step (val)
step 1: MAE=1.6875, RMSE=2.4875, MAPE=5.67%
step 2: MAE=2.0548, RMSE=3.1034, MAPE=6.93%
step 3: MAE=2.1174, RMSE=3.2284, MAPE=7.15%
step 4: MAE=2.1358, RMSE=3.2652, MAPE=7.21%
step 5: MAE=2.1497, RMSE=3.2828, MAPE=7.25%
step 6: MAE=2.1596, RMSE=3.3003, MAPE=7.30%
step 7: MAE=2.1619, RMSE=3.3052, MAPE=7.30%
step 8: MAE=2.1718, RMSE=3.3128, MAPE=7.32%
average: MAE=2.0798, RMSE=3.1607, MAPE=7.02%
test MAE: 2.1259, RMSE: 3.2333, MAPE: 7.16%
performance in each prediction step (test)
step 1: MAE=1.7061, RMSE=2.5035, MAPE=5.72%
step 2: MAE=2.0926, RMSE=3.1618, MAPE=7.03%
step 3: MAE=2.1641, RMSE=3.2986, MAPE=7.29%
step 4: MAE=2.1876, RMSE=3.3430, MAPE=7.37%
step 5: MAE=2.1990, RMSE=3.3654, MAPE=7.40%
step 6: MAE=2.2118, RMSE=3.3907, MAPE=7.45%
step 7: MAE=2.2194, RMSE=3.4003, MAPE=7.48%
step 8: MAE=2.2268, RMSE=3.4031, MAPE=7.50%
average: MAE=2.1259, RMSE=3.2333, MAPE=7.16%
total testing time: 24.3s
total time: 34.7min
