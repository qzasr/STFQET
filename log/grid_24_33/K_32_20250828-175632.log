time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=32, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 9,690,976
**** training model ****
2025-08-28 17:59:50 | epoch: 0001/100, training time: 174.3s, inference time: 4.7s
train loss: 2.7742, val_loss: 2.2511
val loss decrease from inf to 2.2511, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 18:02:47 | epoch: 0002/100, training time: 172.5s, inference time: 4.6s
train loss: 2.4953, val_loss: 2.2030
val loss decrease from 2.2511 to 2.2030, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 18:05:45 | epoch: 0003/100, training time: 173.7s, inference time: 4.6s
train loss: 2.4114, val_loss: 2.1133
val loss decrease from 2.2030 to 2.1133, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 18:08:44 | epoch: 0004/100, training time: 173.9s, inference time: 4.6s
train loss: 2.3303, val_loss: 2.0922
val loss decrease from 2.1133 to 2.0922, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 18:11:42 | epoch: 0005/100, training time: 173.1s, inference time: 4.6s
train loss: 2.3632, val_loss: 2.0676
val loss decrease from 2.0922 to 2.0676, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 18:14:40 | epoch: 0006/100, training time: 174.3s, inference time: 4.6s
train loss: 2.3119, val_loss: 2.1077
2025-08-28 18:17:40 | epoch: 0007/100, training time: 174.6s, inference time: 4.7s
train loss: 2.2999, val_loss: 2.0637
val loss decrease from 2.0676 to 2.0637, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 18:20:39 | epoch: 0008/100, training time: 174.5s, inference time: 4.6s
train loss: 2.2954, val_loss: 2.1069
2025-08-28 18:23:38 | epoch: 0009/100, training time: 174.3s, inference time: 4.6s
train loss: 2.2856, val_loss: 2.0637
2025-08-28 18:26:38 | epoch: 0010/100, training time: 175.9s, inference time: 4.6s
train loss: 2.2993, val_loss: 2.0717
2025-08-28 18:29:38 | epoch: 0011/100, training time: 174.9s, inference time: 4.6s
train loss: 2.2699, val_loss: 2.0882
2025-08-28 18:32:37 | epoch: 0012/100, training time: 174.6s, inference time: 4.6s
train loss: 2.2413, val_loss: 2.0859
2025-08-28 18:35:35 | epoch: 0013/100, training time: 173.7s, inference time: 4.6s
train loss: 2.2240, val_loss: 2.0413
val loss decrease from 2.0637 to 2.0413, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 18:38:34 | epoch: 0014/100, training time: 173.7s, inference time: 4.6s
train loss: 2.2484, val_loss: 2.0893
2025-08-28 18:41:32 | epoch: 0015/100, training time: 173.2s, inference time: 4.6s
train loss: 2.1934, val_loss: 2.0927
2025-08-28 18:44:30 | epoch: 0016/100, training time: 174.0s, inference time: 4.6s
train loss: 2.2132, val_loss: 2.0816
2025-08-28 18:47:29 | epoch: 0017/100, training time: 174.1s, inference time: 4.6s
train loss: 2.1994, val_loss: 2.0392
val loss decrease from 2.0413 to 2.0392, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 18:50:27 | epoch: 0018/100, training time: 173.4s, inference time: 4.6s
train loss: 2.1568, val_loss: 2.0693
2025-08-28 18:53:24 | epoch: 0019/100, training time: 172.8s, inference time: 4.6s
train loss: 2.1655, val_loss: 2.0754
2025-08-28 18:56:23 | epoch: 0020/100, training time: 174.2s, inference time: 4.6s
train loss: 2.1568, val_loss: 2.1162
2025-08-28 18:59:22 | epoch: 0021/100, training time: 174.1s, inference time: 4.6s
train loss: 2.1379, val_loss: 2.1630
2025-08-28 19:02:21 | epoch: 0022/100, training time: 174.4s, inference time: 4.6s
train loss: 2.1493, val_loss: 2.0619
2025-08-28 19:05:20 | epoch: 0023/100, training time: 174.4s, inference time: 4.7s
train loss: 2.1135, val_loss: 2.0765
2025-08-28 19:08:19 | epoch: 0024/100, training time: 174.5s, inference time: 4.6s
train loss: 2.0644, val_loss: 2.0782
2025-08-28 19:11:19 | epoch: 0025/100, training time: 175.2s, inference time: 4.8s
train loss: 2.1108, val_loss: 2.1247
early stop at epoch: 0025
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.7297, RMSE: 2.6858, MAPE: 5.94%
performance in each prediction step (train)
step 1: MAE=1.4924, RMSE=2.2513, MAPE=5.13%
step 2: MAE=1.7489, RMSE=2.7033, MAPE=6.00%
step 3: MAE=1.7452, RMSE=2.7149, MAPE=5.99%
step 4: MAE=1.7393, RMSE=2.7123, MAPE=5.97%
step 5: MAE=1.7469, RMSE=2.7246, MAPE=5.99%
step 6: MAE=1.7569, RMSE=2.7445, MAPE=6.03%
step 7: MAE=1.7796, RMSE=2.7811, MAPE=6.12%
step 8: MAE=1.8287, RMSE=2.8542, MAPE=6.31%
average: MAE=1.7297, RMSE=2.6858, MAPE=5.94%
val MAE: 2.1244, RMSE: 3.2797, MAPE: 7.37%
performance in each prediction step (val)
step 1: MAE=1.7232, RMSE=2.5790, MAPE=5.96%
step 2: MAE=2.1020, RMSE=3.2320, MAPE=7.29%
step 3: MAE=2.1580, RMSE=3.3441, MAPE=7.49%
step 4: MAE=2.1779, RMSE=3.3825, MAPE=7.55%
step 5: MAE=2.1915, RMSE=3.4022, MAPE=7.59%
step 6: MAE=2.2027, RMSE=3.4193, MAPE=7.64%
step 7: MAE=2.2115, RMSE=3.4300, MAPE=7.67%
step 8: MAE=2.2285, RMSE=3.4482, MAPE=7.73%
average: MAE=2.1244, RMSE=3.2797, MAPE=7.37%
test MAE: 2.1568, RMSE: 3.3070, MAPE: 7.48%
performance in each prediction step (test)
step 1: MAE=1.7340, RMSE=2.5711, MAPE=6.01%
step 2: MAE=2.1300, RMSE=3.2449, MAPE=7.38%
step 3: MAE=2.1923, RMSE=3.3669, MAPE=7.60%
step 4: MAE=2.2149, RMSE=3.4155, MAPE=7.68%
step 5: MAE=2.2296, RMSE=3.4390, MAPE=7.73%
step 6: MAE=2.2435, RMSE=3.4632, MAPE=7.79%
step 7: MAE=2.2496, RMSE=3.4708, MAPE=7.82%
step 8: MAE=2.2606, RMSE=3.4849, MAPE=7.86%
average: MAE=2.1568, RMSE=3.3070, MAPE=7.48%
total testing time: 47.2s
total time: 75.5min
