time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=4, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 189,120
**** training model ****
2025-08-28 14:40:45 | epoch: 0001/100, training time: 75.0s, inference time: 2.2s
train loss: 2.9540, val_loss: 2.2801
val loss decrease from inf to 2.2801, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 14:42:00 | epoch: 0002/100, training time: 73.5s, inference time: 2.2s
train loss: 2.5669, val_loss: 2.1884
val loss decrease from 2.2801 to 2.1884, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 14:43:19 | epoch: 0003/100, training time: 76.6s, inference time: 2.2s
train loss: 2.4978, val_loss: 2.1354
val loss decrease from 2.1884 to 2.1354, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 14:44:34 | epoch: 0004/100, training time: 72.8s, inference time: 2.3s
train loss: 2.4554, val_loss: 2.1418
2025-08-28 14:45:49 | epoch: 0005/100, training time: 72.0s, inference time: 2.2s
train loss: 2.4314, val_loss: 2.1382
2025-08-28 14:47:06 | epoch: 0006/100, training time: 75.1s, inference time: 2.3s
train loss: 2.4006, val_loss: 2.0745
val loss decrease from 2.1354 to 2.0745, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 14:48:22 | epoch: 0007/100, training time: 74.1s, inference time: 2.2s
train loss: 2.4036, val_loss: 2.1826
2025-08-28 14:49:41 | epoch: 0008/100, training time: 76.6s, inference time: 2.3s
train loss: 2.3833, val_loss: 2.0832
2025-08-28 14:50:59 | epoch: 0009/100, training time: 75.2s, inference time: 2.3s
train loss: 2.3778, val_loss: 2.0993
2025-08-28 14:52:12 | epoch: 0010/100, training time: 71.4s, inference time: 2.3s
train loss: 2.3543, val_loss: 2.0511
val loss decrease from 2.0745 to 2.0511, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 14:53:29 | epoch: 0011/100, training time: 74.1s, inference time: 2.2s
train loss: 2.3466, val_loss: 2.0678
2025-08-28 14:54:41 | epoch: 0012/100, training time: 70.6s, inference time: 2.2s
train loss: 2.3328, val_loss: 2.0739
2025-08-28 14:56:00 | epoch: 0013/100, training time: 75.9s, inference time: 2.3s
train loss: 2.3216, val_loss: 2.0810
2025-08-28 14:57:18 | epoch: 0014/100, training time: 75.9s, inference time: 2.3s
train loss: 2.3086, val_loss: 2.1278
2025-08-28 14:58:35 | epoch: 0015/100, training time: 74.8s, inference time: 2.2s
train loss: 2.3263, val_loss: 2.0982
2025-08-28 14:59:51 | epoch: 0016/100, training time: 73.6s, inference time: 2.2s
train loss: 2.3365, val_loss: 2.0804
2025-08-28 15:01:08 | epoch: 0017/100, training time: 74.8s, inference time: 2.3s
train loss: 2.3084, val_loss: 2.0845
2025-08-28 15:02:25 | epoch: 0018/100, training time: 75.1s, inference time: 2.2s
train loss: 2.2869, val_loss: 2.0370
val loss decrease from 2.0511 to 2.0370, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 15:03:36 | epoch: 0019/100, training time: 69.3s, inference time: 2.2s
train loss: 2.3059, val_loss: 2.0616
2025-08-28 15:04:49 | epoch: 0020/100, training time: 70.6s, inference time: 2.2s
train loss: 2.2981, val_loss: 2.0694
2025-08-28 15:06:06 | epoch: 0021/100, training time: 74.6s, inference time: 2.2s
train loss: 2.3159, val_loss: 2.0279
val loss decrease from 2.0370 to 2.0279, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 15:07:25 | epoch: 0022/100, training time: 76.5s, inference time: 2.3s
train loss: 2.2941, val_loss: 2.0498
2025-08-28 15:08:45 | epoch: 0023/100, training time: 76.9s, inference time: 2.7s
train loss: 2.2984, val_loss: 2.0651
2025-08-28 15:10:04 | epoch: 0024/100, training time: 77.0s, inference time: 2.2s
train loss: 2.2878, val_loss: 2.0796
2025-08-28 15:11:17 | epoch: 0025/100, training time: 71.0s, inference time: 2.2s
train loss: 2.2717, val_loss: 2.0633
2025-08-28 15:12:33 | epoch: 0026/100, training time: 74.0s, inference time: 2.2s
train loss: 2.2701, val_loss: 2.0962
2025-08-28 15:13:49 | epoch: 0027/100, training time: 73.4s, inference time: 2.2s
train loss: 2.2633, val_loss: 2.0527
2025-08-28 15:15:05 | epoch: 0028/100, training time: 73.4s, inference time: 2.2s
train loss: 2.2685, val_loss: 2.0931
2025-08-28 15:16:24 | epoch: 0029/100, training time: 76.9s, inference time: 2.3s
train loss: 2.2656, val_loss: 2.0247
val loss decrease from 2.0279 to 2.0247, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-28 15:17:39 | epoch: 0030/100, training time: 72.8s, inference time: 2.3s
train loss: 2.2882, val_loss: 2.0411
2025-08-28 15:18:55 | epoch: 0031/100, training time: 74.0s, inference time: 2.3s
train loss: 2.2913, val_loss: 2.0619
2025-08-28 15:20:10 | epoch: 0032/100, training time: 72.6s, inference time: 2.3s
train loss: 2.2706, val_loss: 2.0503
2025-08-28 15:21:27 | epoch: 0033/100, training time: 74.4s, inference time: 2.2s
train loss: 2.2295, val_loss: 2.0603
2025-08-28 15:22:45 | epoch: 0034/100, training time: 75.7s, inference time: 2.3s
train loss: 2.2617, val_loss: 2.0619
2025-08-28 15:24:00 | epoch: 0035/100, training time: 73.5s, inference time: 2.3s
train loss: 2.2204, val_loss: 2.0621
2025-08-28 15:25:17 | epoch: 0036/100, training time: 73.8s, inference time: 2.3s
train loss: 2.2424, val_loss: 2.0626
2025-08-28 15:26:33 | epoch: 0037/100, training time: 74.0s, inference time: 2.2s
train loss: 2.2787, val_loss: 2.0642
early stop at epoch: 0037
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.8761, RMSE: 2.8805, MAPE: 6.45%
performance in each prediction step (train)
step 1: MAE=1.5705, RMSE=2.3459, MAPE=5.41%
step 2: MAE=1.8780, RMSE=2.8711, MAPE=6.45%
step 3: MAE=1.9105, RMSE=2.9392, MAPE=6.57%
step 4: MAE=1.9106, RMSE=2.9439, MAPE=6.57%
step 5: MAE=1.9135, RMSE=2.9512, MAPE=6.58%
step 6: MAE=1.9213, RMSE=2.9674, MAPE=6.61%
step 7: MAE=1.9360, RMSE=2.9912, MAPE=6.66%
step 8: MAE=1.9685, RMSE=3.0339, MAPE=6.78%
average: MAE=1.8761, RMSE=2.8805, MAPE=6.45%
val MAE: 2.0642, RMSE: 3.1524, MAPE: 7.08%
performance in each prediction step (val)
step 1: MAE=1.6727, RMSE=2.4693, MAPE=5.73%
step 2: MAE=2.0339, RMSE=3.0684, MAPE=6.97%
step 3: MAE=2.0973, RMSE=3.2105, MAPE=7.21%
step 4: MAE=2.1164, RMSE=3.2602, MAPE=7.27%
step 5: MAE=2.1304, RMSE=3.2845, MAPE=7.32%
step 6: MAE=2.1426, RMSE=3.2987, MAPE=7.35%
step 7: MAE=2.1511, RMSE=3.3074, MAPE=7.37%
step 8: MAE=2.1692, RMSE=3.3203, MAPE=7.43%
average: MAE=2.0642, RMSE=3.1524, MAPE=7.08%
test MAE: 2.0924, RMSE: 3.1902, MAPE: 7.18%
performance in each prediction step (test)
step 1: MAE=1.6791, RMSE=2.4605, MAPE=5.76%
step 2: MAE=2.0504, RMSE=3.0988, MAPE=7.03%
step 3: MAE=2.1193, RMSE=3.2409, MAPE=7.28%
step 4: MAE=2.1437, RMSE=3.2880, MAPE=7.36%
step 5: MAE=2.1620, RMSE=3.3167, MAPE=7.42%
step 6: MAE=2.1796, RMSE=3.3475, MAPE=7.48%
step 7: MAE=2.1938, RMSE=3.3732, MAPE=7.53%
step 8: MAE=2.2115, RMSE=3.3956, MAPE=7.59%
average: MAE=2.0924, RMSE=3.1902, MAPE=7.18%
total testing time: 23.4s
total time: 47.8min
