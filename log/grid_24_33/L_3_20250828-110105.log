time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=3, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 944,458
**** training model ****
2025-08-25 08:55:32 | epoch: 0001/100, training time: 89.9s, inference time: 3.2s
train loss: 2.8472, val_loss: 2.2009
val loss decrease from inf to 2.2009, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 08:57:13 | epoch: 0002/100, training time: 97.2s, inference time: 3.1s
train loss: 2.5181, val_loss: 2.1477
val loss decrease from 2.2009 to 2.1477, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 08:58:54 | epoch: 0003/100, training time: 98.5s, inference time: 3.1s
train loss: 2.4014, val_loss: 2.1148
val loss decrease from 2.1477 to 2.1148, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 09:00:35 | epoch: 0004/100, training time: 97.7s, inference time: 3.2s
train loss: 2.3713, val_loss: 2.0986
val loss decrease from 2.1148 to 2.0986, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 09:02:16 | epoch: 0005/100, training time: 97.2s, inference time: 3.1s
train loss: 2.4083, val_loss: 2.0749
val loss decrease from 2.0986 to 2.0749, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 09:03:53 | epoch: 0006/100, training time: 94.6s, inference time: 3.0s
train loss: 2.3528, val_loss: 2.0801
2025-08-25 09:05:30 | epoch: 0007/100, training time: 93.5s, inference time: 3.0s
train loss: 2.3410, val_loss: 2.0692
val loss decrease from 2.0749 to 2.0692, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 09:07:10 | epoch: 0008/100, training time: 96.7s, inference time: 3.2s
train loss: 2.3078, val_loss: 2.1145
2025-08-25 09:08:46 | epoch: 0009/100, training time: 93.5s, inference time: 3.0s
train loss: 2.2926, val_loss: 2.1110
2025-08-25 09:10:27 | epoch: 0010/100, training time: 98.0s, inference time: 3.0s
train loss: 2.2715, val_loss: 2.0506
val loss decrease from 2.0692 to 2.0506, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 09:12:10 | epoch: 0011/100, training time: 99.9s, inference time: 3.0s
train loss: 2.2879, val_loss: 2.0756
2025-08-25 09:13:52 | epoch: 0012/100, training time: 98.4s, inference time: 3.2s
train loss: 2.2983, val_loss: 2.0514
2025-08-25 09:15:33 | epoch: 0013/100, training time: 98.5s, inference time: 3.2s
train loss: 2.2738, val_loss: 2.0549
2025-08-25 09:17:14 | epoch: 0014/100, training time: 98.1s, inference time: 3.1s
train loss: 2.2825, val_loss: 2.0468
val loss decrease from 2.0506 to 2.0468, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 09:18:56 | epoch: 0015/100, training time: 98.1s, inference time: 3.2s
train loss: 2.2457, val_loss: 2.0398
val loss decrease from 2.0468 to 2.0398, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 09:20:37 | epoch: 0016/100, training time: 98.0s, inference time: 3.1s
train loss: 2.2462, val_loss: 2.0164
val loss decrease from 2.0398 to 2.0164, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-25 09:22:12 | epoch: 0017/100, training time: 92.2s, inference time: 3.0s
train loss: 2.2422, val_loss: 2.0665
2025-08-25 09:23:48 | epoch: 0018/100, training time: 93.5s, inference time: 3.0s
train loss: 2.2395, val_loss: 2.0544
2025-08-25 09:25:27 | epoch: 0019/100, training time: 95.7s, inference time: 3.0s
train loss: 2.2111, val_loss: 2.0470
2025-08-25 09:27:05 | epoch: 0020/100, training time: 94.4s, inference time: 3.1s
train loss: 2.2355, val_loss: 2.0596
2025-08-25 09:28:43 | epoch: 0021/100, training time: 95.7s, inference time: 3.0s
train loss: 2.2076, val_loss: 2.0548
2025-08-25 09:30:19 | epoch: 0022/100, training time: 92.3s, inference time: 2.9s
train loss: 2.1919, val_loss: 2.0567
2025-08-25 09:31:59 | epoch: 0023/100, training time: 97.6s, inference time: 3.1s
train loss: 2.1895, val_loss: 2.0672
2025-08-25 09:33:44 | epoch: 0024/100, training time: 101.3s, inference time: 3.5s
train loss: 2.2080, val_loss: 2.0714
early stop at epoch: 0024
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.8482, RMSE: 2.8298, MAPE: 6.40%
performance in each prediction step (train)
step 1: MAE=1.5469, RMSE=2.3268, MAPE=5.31%
step 2: MAE=1.8523, RMSE=2.8343, MAPE=6.38%
step 3: MAE=1.8816, RMSE=2.8883, MAPE=6.51%
step 4: MAE=1.8820, RMSE=2.8894, MAPE=6.51%
step 5: MAE=1.8867, RMSE=2.8941, MAPE=6.54%
step 6: MAE=1.8907, RMSE=2.9027, MAPE=6.56%
step 7: MAE=1.9050, RMSE=2.9244, MAPE=6.63%
step 8: MAE=1.9402, RMSE=2.9788, MAPE=6.76%
average: MAE=1.8482, RMSE=2.8298, MAPE=6.40%
val MAE: 2.0693, RMSE: 3.1683, MAPE: 7.16%
performance in each prediction step (val)
step 1: MAE=1.6706, RMSE=2.4921, MAPE=5.72%
step 2: MAE=2.0438, RMSE=3.1110, MAPE=7.07%
step 3: MAE=2.1113, RMSE=3.2398, MAPE=7.32%
step 4: MAE=2.1271, RMSE=3.2736, MAPE=7.37%
step 5: MAE=2.1403, RMSE=3.2960, MAPE=7.42%
step 6: MAE=2.1449, RMSE=3.3026, MAPE=7.44%
step 7: MAE=2.1506, RMSE=3.3066, MAPE=7.46%
step 8: MAE=2.1656, RMSE=3.3250, MAPE=7.51%
average: MAE=2.0693, RMSE=3.1683, MAPE=7.16%
test MAE: 2.1246, RMSE: 3.2410, MAPE: 7.37%
performance in each prediction step (test)
step 1: MAE=1.6941, RMSE=2.4927, MAPE=5.81%
step 2: MAE=2.0963, RMSE=3.1770, MAPE=7.24%
step 3: MAE=2.1732, RMSE=3.3275, MAPE=7.53%
step 4: MAE=2.1927, RMSE=3.3680, MAPE=7.60%
step 5: MAE=2.2046, RMSE=3.3883, MAPE=7.66%
step 6: MAE=2.2071, RMSE=3.3883, MAPE=7.68%
step 7: MAE=2.2092, RMSE=3.3883, MAPE=7.69%
step 8: MAE=2.2192, RMSE=3.3982, MAPE=7.72%
average: MAE=2.1246, RMSE=3.2410, MAPE=7.37%
total testing time: 29.9s
total time: 40.5min
