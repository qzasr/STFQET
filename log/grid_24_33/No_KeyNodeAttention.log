time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=11, patience=8, learning_rate=0.003, decay_epoch=10, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test_20251010_060548.pth', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.01, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.1, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.1, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 639,264
**** training model ****
2025-10-10 06:07:05 | epoch: 0001/11, training time: 58.1s, inference time: 1.6s
train loss: 2.8225, val_loss: 2.2226
val loss decrease from inf to 2.2226, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_060548.pth
2025-10-10 06:08:00 | epoch: 0002/11, training time: 53.7s, inference time: 1.5s
train loss: 2.4946, val_loss: 2.1722
val loss decrease from 2.2226 to 2.1722, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_060548.pth
2025-10-10 06:08:57 | epoch: 0003/11, training time: 56.0s, inference time: 1.5s
train loss: 2.4246, val_loss: 2.0804
val loss decrease from 2.1722 to 2.0804, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_060548.pth
2025-10-10 06:09:47 | epoch: 0004/11, training time: 48.3s, inference time: 1.5s
train loss: 2.3975, val_loss: 2.1443
2025-10-10 06:10:39 | epoch: 0005/11, training time: 50.1s, inference time: 1.5s
train loss: 2.3711, val_loss: 2.0965
2025-10-10 06:11:30 | epoch: 0006/11, training time: 49.4s, inference time: 1.5s
train loss: 2.3659, val_loss: 2.1198
2025-10-10 06:12:19 | epoch: 0007/11, training time: 48.2s, inference time: 1.5s
train loss: 2.3418, val_loss: 2.0580
val loss decrease from 2.0804 to 2.0580, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_060548.pth
2025-10-10 06:13:10 | epoch: 0008/11, training time: 48.8s, inference time: 1.5s
train loss: 2.3434, val_loss: 2.1164
2025-10-10 06:14:00 | epoch: 0009/11, training time: 49.0s, inference time: 1.5s
train loss: 2.3256, val_loss: 2.0568
val loss decrease from 2.0580 to 2.0568, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_060548.pth
2025-10-10 06:14:50 | epoch: 0010/11, training time: 48.6s, inference time: 1.5s
train loss: 2.3066, val_loss: 2.0666
2025-10-10 06:15:40 | epoch: 0011/11, training time: 48.0s, inference time: 1.5s
train loss: 2.3020, val_loss: 2.0325
val loss decrease from 2.0568 to 2.0325, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_060548.pth
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test_20251010_060548.pth
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test_20251010_060548.pth
model loaded!
evaluating...
train MAE: 1.9179, RMSE: 2.9577, MAPE: 6.57%
performance in each prediction step (train)
step 1: MAE=1.5914, RMSE=2.4018, MAPE=5.38%
step 2: MAE=1.9123, RMSE=2.9421, MAPE=6.50%
step 3: MAE=1.9556, RMSE=3.0209, MAPE=6.68%
step 4: MAE=1.9632, RMSE=3.0365, MAPE=6.73%
step 5: MAE=1.9671, RMSE=3.0459, MAPE=6.76%
step 6: MAE=1.9736, RMSE=3.0575, MAPE=6.80%
step 7: MAE=1.9805, RMSE=3.0657, MAPE=6.83%
step 8: MAE=1.9997, RMSE=3.0914, MAPE=6.91%
average: MAE=1.9179, RMSE=2.9577, MAPE=6.57%
val MAE: 2.0328, RMSE: 3.1026, MAPE: 6.93%
performance in each prediction step (val)
step 1: MAE=1.6583, RMSE=2.4798, MAPE=5.58%
step 2: MAE=2.0160, RMSE=3.0485, MAPE=6.84%
step 3: MAE=2.0767, RMSE=3.1630, MAPE=7.08%
step 4: MAE=2.0883, RMSE=3.1987, MAPE=7.14%
step 5: MAE=2.0966, RMSE=3.2207, MAPE=7.17%
step 6: MAE=2.1032, RMSE=3.2348, MAPE=7.19%
step 7: MAE=2.1083, RMSE=3.2387, MAPE=7.22%
step 8: MAE=2.1149, RMSE=3.2364, MAPE=7.24%
average: MAE=2.0328, RMSE=3.1026, MAPE=6.93%
test MAE: 2.0698, RMSE: 3.1736, MAPE: 7.05%
performance in each prediction step (test)
step 1: MAE=1.6614, RMSE=2.4657, MAPE=5.58%
step 2: MAE=2.0460, RMSE=3.1184, MAPE=6.93%
step 3: MAE=2.1119, RMSE=3.2470, MAPE=7.18%
step 4: MAE=2.1307, RMSE=3.2863, MAPE=7.26%
step 5: MAE=2.1405, RMSE=3.3039, MAPE=7.31%
step 6: MAE=2.1484, RMSE=3.3182, MAPE=7.34%
step 7: MAE=2.1543, RMSE=3.3196, MAPE=7.37%
step 8: MAE=2.1653, RMSE=3.3300, MAPE=7.41%
average: MAE=2.0698, RMSE=3.1736, MAPE=7.05%
total testing time: 15.0s
total time: 10.1min
