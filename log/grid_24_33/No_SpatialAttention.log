time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=10, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.01, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.1, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.1, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 639,264
**** training model ****
2025-09-02 02:58:46 | epoch: 0001/100, training time: 53.8s, inference time: 1.8s
train loss: 2.7921, val_loss: 2.2703
val loss decrease from inf to 2.2703, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-09-02 02:59:43 | epoch: 0002/100, training time: 55.4s, inference time: 1.8s
train loss: 2.4973, val_loss: 2.1665
val loss decrease from 2.2703 to 2.1665, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-09-02 03:00:41 | epoch: 0003/100, training time: 55.8s, inference time: 1.8s
train loss: 2.4333, val_loss: 2.1082
val loss decrease from 2.1665 to 2.1082, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-09-02 03:01:35 | epoch: 0004/100, training time: 52.7s, inference time: 1.7s
train loss: 2.4111, val_loss: 2.1488
2025-09-02 03:02:29 | epoch: 0005/100, training time: 52.0s, inference time: 1.7s
train loss: 2.3911, val_loss: 2.0766
val loss decrease from 2.1082 to 2.0766, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-09-02 03:03:22 | epoch: 0006/100, training time: 51.6s, inference time: 1.7s
train loss: 2.3865, val_loss: 2.1158
2025-09-02 03:04:20 | epoch: 0007/100, training time: 55.7s, inference time: 1.7s
train loss: 2.3703, val_loss: 2.1003
2025-09-02 03:05:13 | epoch: 0008/100, training time: 51.5s, inference time: 1.7s
train loss: 2.3728, val_loss: 2.1051
2025-09-02 03:06:07 | epoch: 0009/100, training time: 52.6s, inference time: 1.8s
train loss: 2.3630, val_loss: 2.0798
2025-09-02 03:07:01 | epoch: 0010/100, training time: 51.4s, inference time: 1.7s
train loss: 2.3419, val_loss: 2.0674
val loss decrease from 2.0766 to 2.0674, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-09-02 03:07:54 | epoch: 0011/100, training time: 52.0s, inference time: 1.7s
train loss: 2.3423, val_loss: 2.0411
val loss decrease from 2.0674 to 2.0411, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-09-02 03:08:53 | epoch: 0012/100, training time: 57.1s, inference time: 1.8s
train loss: 2.3321, val_loss: 2.0707
2025-09-02 03:09:47 | epoch: 0013/100, training time: 52.2s, inference time: 1.7s
train loss: 2.3342, val_loss: 2.1580
2025-09-02 03:10:40 | epoch: 0014/100, training time: 51.6s, inference time: 1.7s
train loss: 2.3339, val_loss: 2.1039
2025-09-02 03:11:35 | epoch: 0015/100, training time: 52.6s, inference time: 1.8s
train loss: 2.2927, val_loss: 2.1121
2025-09-02 03:12:34 | epoch: 0016/100, training time: 57.2s, inference time: 1.7s
train loss: 2.2941, val_loss: 2.1657
2025-09-02 03:13:29 | epoch: 0017/100, training time: 53.5s, inference time: 1.8s
train loss: 2.3207, val_loss: 2.0774
2025-09-02 03:14:22 | epoch: 0018/100, training time: 51.3s, inference time: 1.7s
train loss: 2.2861, val_loss: 2.0547
2025-09-02 03:15:15 | epoch: 0019/100, training time: 51.7s, inference time: 1.7s
train loss: 2.2794, val_loss: 2.0618
early stop at epoch: 0019
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.9845, RMSE: 3.0355, MAPE: 6.79%
performance in each prediction step (train)
step 1: MAE=1.6540, RMSE=2.4476, MAPE=5.62%
step 2: MAE=1.9696, RMSE=2.9935, MAPE=6.70%
step 3: MAE=2.0132, RMSE=3.0839, MAPE=6.87%
step 4: MAE=2.0225, RMSE=3.1061, MAPE=6.92%
step 5: MAE=2.0313, RMSE=3.1239, MAPE=6.96%
step 6: MAE=2.0425, RMSE=3.1429, MAPE=7.01%
step 7: MAE=2.0566, RMSE=3.1702, MAPE=7.07%
step 8: MAE=2.0859, RMSE=3.2159, MAPE=7.17%
average: MAE=1.9845, RMSE=3.0355, MAPE=6.79%
val MAE: 2.0624, RMSE: 3.1247, MAPE: 7.04%
performance in each prediction step (val)
step 1: MAE=1.6948, RMSE=2.4781, MAPE=5.73%
step 2: MAE=2.0380, RMSE=3.0546, MAPE=6.93%
step 3: MAE=2.0964, RMSE=3.1748, MAPE=7.16%
step 4: MAE=2.1110, RMSE=3.2162, MAPE=7.22%
step 5: MAE=2.1220, RMSE=3.2399, MAPE=7.25%
step 6: MAE=2.1310, RMSE=3.2532, MAPE=7.28%
step 7: MAE=2.1424, RMSE=3.2733, MAPE=7.32%
step 8: MAE=2.1638, RMSE=3.3075, MAPE=7.39%
average: MAE=2.0624, RMSE=3.1247, MAPE=7.04%
test MAE: 2.1100, RMSE: 3.2031, MAPE: 7.20%
performance in each prediction step (test)
step 1: MAE=1.7128, RMSE=2.4999, MAPE=5.79%
step 2: MAE=2.0744, RMSE=3.1194, MAPE=7.05%
step 3: MAE=2.1420, RMSE=3.2633, MAPE=7.31%
step 4: MAE=2.1622, RMSE=3.3058, MAPE=7.39%
step 5: MAE=2.1762, RMSE=3.3270, MAPE=7.44%
step 6: MAE=2.1867, RMSE=3.3426, MAPE=7.49%
step 7: MAE=2.2006, RMSE=3.3654, MAPE=7.54%
step 8: MAE=2.2252, RMSE=3.4010, MAPE=7.62%
average: MAE=2.1100, RMSE=3.2031, MAPE=7.20%
total testing time: 17.4s
total time: 18.0min
