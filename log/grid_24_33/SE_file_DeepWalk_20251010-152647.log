time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=10, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/DeepWalk_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test_20251010_152649.pth', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.01, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.1, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.1, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 655,648
**** training model ****
2025-10-10 14:48:31 | epoch: 0001/11, training time: 78.8s, inference time: 2.5s
train loss: 2.7872, val_loss: 2.2500
val loss decrease from inf to 2.2500, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
2025-10-10 14:49:50 | epoch: 0002/11, training time: 76.5s, inference time: 2.2s
train loss: 2.5270, val_loss: 2.2411
val loss decrease from 2.2500 to 2.2411, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
2025-10-10 14:51:00 | epoch: 0003/11, training time: 68.2s, inference time: 2.1s
train loss: 2.4438, val_loss: 2.2056
val loss decrease from 2.2411 to 2.2056, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
2025-10-10 14:52:15 | epoch: 0004/11, training time: 72.9s, inference time: 2.2s
train loss: 2.4106, val_loss: 2.1207
val loss decrease from 2.2056 to 2.1207, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
2025-10-10 14:53:27 | epoch: 0005/11, training time: 69.8s, inference time: 2.2s
train loss: 2.4021, val_loss: 2.0861
val loss decrease from 2.1207 to 2.0861, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
2025-10-10 14:54:37 | epoch: 0006/11, training time: 67.3s, inference time: 2.1s
train loss: 2.3747, val_loss: 2.0939
2025-10-10 14:55:49 | epoch: 0007/11, training time: 69.6s, inference time: 2.5s
train loss: 2.3704, val_loss: 2.0787
val loss decrease from 2.0861 to 2.0787, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
2025-10-10 14:57:07 | epoch: 0008/11, training time: 75.7s, inference time: 2.1s
train loss: 2.3639, val_loss: 2.0729
val loss decrease from 2.0787 to 2.0729, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
2025-10-10 14:58:17 | epoch: 0009/11, training time: 68.2s, inference time: 2.1s
train loss: 2.3479, val_loss: 2.0980
2025-10-10 14:59:32 | epoch: 0010/11, training time: 72.1s, inference time: 2.5s
train loss: 2.3411, val_loss: 2.1306
2025-10-10 15:00:51 | epoch: 0011/11, training time: 77.0s, inference time: 2.2s
train loss: 2.3126, val_loss: 2.0682
val loss decrease from 2.0729 to 2.0682, saving model to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test_20251010_144653.pth
model loaded!
evaluating...
train MAE: 1.9649, RMSE: 3.0047, MAPE: 6.62%
performance in each prediction step (train)
step 1: MAE=1.6600, RMSE=2.4647, MAPE=5.53%
step 2: MAE=1.9585, RMSE=2.9826, MAPE=6.55%
step 3: MAE=1.9953, RMSE=3.0586, MAPE=6.70%
step 4: MAE=1.9988, RMSE=3.0747, MAPE=6.73%
step 5: MAE=2.0033, RMSE=3.0837, MAPE=6.76%
step 6: MAE=2.0140, RMSE=3.0975, MAPE=6.81%
step 7: MAE=2.0323, RMSE=3.1190, MAPE=6.87%
step 8: MAE=2.0573, RMSE=3.1566, MAPE=6.97%
average: MAE=1.9649, RMSE=3.0047, MAPE=6.62%
val MAE: 2.0677, RMSE: 3.1281, MAPE: 6.95%
performance in each prediction step (val)
step 1: MAE=1.7205, RMSE=2.5149, MAPE=5.71%
step 2: MAE=2.0480, RMSE=3.0666, MAPE=6.85%
step 3: MAE=2.1000, RMSE=3.1816, MAPE=7.06%
step 4: MAE=2.1113, RMSE=3.2182, MAPE=7.11%
step 5: MAE=2.1199, RMSE=3.2358, MAPE=7.15%
step 6: MAE=2.1299, RMSE=3.2524, MAPE=7.18%
step 7: MAE=2.1465, RMSE=3.2669, MAPE=7.24%
step 8: MAE=2.1656, RMSE=3.2886, MAPE=7.31%
average: MAE=2.0677, RMSE=3.1281, MAPE=6.95%
test MAE: 2.1076, RMSE: 3.2066, MAPE: 7.08%
performance in each prediction step (test)
step 1: MAE=1.7286, RMSE=2.5187, MAPE=5.75%
step 2: MAE=2.0755, RMSE=3.1230, MAPE=6.94%
step 3: MAE=2.1365, RMSE=3.2624, MAPE=7.17%
step 4: MAE=2.1553, RMSE=3.3084, MAPE=7.25%
step 5: MAE=2.1685, RMSE=3.3336, MAPE=7.30%
step 6: MAE=2.1833, RMSE=3.3525, MAPE=7.36%
step 7: MAE=2.1990, RMSE=3.3687, MAPE=7.41%
step 8: MAE=2.2137, RMSE=3.3851, MAPE=7.47%
average: MAE=2.1076, RMSE=3.2066, MAPE=7.08%
total testing time: 21.4s
total time: 14.3min
