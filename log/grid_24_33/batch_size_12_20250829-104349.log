time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=12, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 655,648
**** training model ****
2025-08-29 10:45:05 | epoch: 0001/100, training time: 56.6s, inference time: 1.7s
train loss: 2.7347, val_loss: 2.2019
val loss decrease from inf to 2.2019, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 10:46:04 | epoch: 0002/100, training time: 57.0s, inference time: 1.6s
train loss: 2.4102, val_loss: 2.2035
2025-08-29 10:47:02 | epoch: 0003/100, training time: 56.5s, inference time: 1.7s
train loss: 2.3368, val_loss: 2.1509
val loss decrease from 2.2019 to 2.1509, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 10:48:01 | epoch: 0004/100, training time: 57.0s, inference time: 1.6s
train loss: 2.3081, val_loss: 2.1011
val loss decrease from 2.1509 to 2.1011, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 10:48:59 | epoch: 0005/100, training time: 56.5s, inference time: 1.6s
train loss: 2.2758, val_loss: 2.1437
2025-08-29 10:49:58 | epoch: 0006/100, training time: 57.3s, inference time: 1.6s
train loss: 2.2668, val_loss: 2.0606
val loss decrease from 2.1011 to 2.0606, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 10:50:56 | epoch: 0007/100, training time: 56.6s, inference time: 1.6s
train loss: 2.2484, val_loss: 2.0340
val loss decrease from 2.0606 to 2.0340, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 10:51:55 | epoch: 0008/100, training time: 57.4s, inference time: 1.6s
train loss: 2.2395, val_loss: 2.0538
2025-08-29 10:52:54 | epoch: 0009/100, training time: 57.5s, inference time: 1.6s
train loss: 2.2431, val_loss: 2.0761
2025-08-29 10:53:53 | epoch: 0010/100, training time: 57.1s, inference time: 1.6s
train loss: 2.2324, val_loss: 2.1165
2025-08-29 10:54:51 | epoch: 0011/100, training time: 56.8s, inference time: 1.6s
train loss: 2.1764, val_loss: 2.0938
2025-08-29 10:55:49 | epoch: 0012/100, training time: 55.4s, inference time: 1.6s
train loss: 2.2139, val_loss: 2.0253
val loss decrease from 2.0340 to 2.0253, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 10:56:43 | epoch: 0013/100, training time: 53.1s, inference time: 1.6s
train loss: 2.1781, val_loss: 2.0619
2025-08-29 10:57:38 | epoch: 0014/100, training time: 52.8s, inference time: 1.6s
train loss: 2.1545, val_loss: 2.0579
2025-08-29 10:58:32 | epoch: 0015/100, training time: 52.9s, inference time: 1.6s
train loss: 2.1742, val_loss: 2.0446
2025-08-29 10:59:27 | epoch: 0016/100, training time: 53.5s, inference time: 1.6s
train loss: 2.1474, val_loss: 2.0541
2025-08-29 11:00:22 | epoch: 0017/100, training time: 53.0s, inference time: 1.7s
train loss: 2.1582, val_loss: 2.0429
2025-08-29 11:01:17 | epoch: 0018/100, training time: 53.6s, inference time: 1.6s
train loss: 2.1329, val_loss: 2.0314
2025-08-29 11:02:12 | epoch: 0019/100, training time: 52.9s, inference time: 1.7s
train loss: 2.1618, val_loss: 2.1023
2025-08-29 11:03:06 | epoch: 0020/100, training time: 53.0s, inference time: 1.6s
train loss: 2.1266, val_loss: 2.0988
early stop at epoch: 0020
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.9225, RMSE: 2.9277, MAPE: 6.69%
performance in each prediction step (train)
step 1: MAE=1.6211, RMSE=2.3959, MAPE=5.62%
step 2: MAE=1.9217, RMSE=2.9044, MAPE=6.65%
step 3: MAE=1.9539, RMSE=2.9722, MAPE=6.77%
step 4: MAE=1.9560, RMSE=2.9827, MAPE=6.80%
step 5: MAE=1.9553, RMSE=2.9888, MAPE=6.82%
step 6: MAE=1.9674, RMSE=3.0135, MAPE=6.87%
step 7: MAE=1.9851, RMSE=3.0501, MAPE=6.93%
step 8: MAE=2.0194, RMSE=3.1141, MAPE=7.06%
average: MAE=1.9225, RMSE=2.9277, MAPE=6.69%
val MAE: 2.0991, RMSE: 3.1987, MAPE: 7.27%
performance in each prediction step (val)
step 1: MAE=1.7391, RMSE=2.5602, MAPE=5.98%
step 2: MAE=2.0802, RMSE=3.1258, MAPE=7.17%
step 3: MAE=2.1370, RMSE=3.2523, MAPE=7.39%
step 4: MAE=2.1500, RMSE=3.2932, MAPE=7.45%
step 5: MAE=2.1578, RMSE=3.3163, MAPE=7.49%
step 6: MAE=2.1646, RMSE=3.3315, MAPE=7.52%
step 7: MAE=2.1768, RMSE=3.3491, MAPE=7.55%
step 8: MAE=2.1875, RMSE=3.3610, MAPE=7.59%
average: MAE=2.0991, RMSE=3.1987, MAPE=7.27%
test MAE: 2.1317, RMSE: 3.2362, MAPE: 7.40%
performance in each prediction step (test)
step 1: MAE=1.7357, RMSE=2.5267, MAPE=5.99%
step 2: MAE=2.1061, RMSE=3.1614, MAPE=7.28%
step 3: MAE=2.1745, RMSE=3.3112, MAPE=7.53%
step 4: MAE=2.1900, RMSE=3.3427, MAPE=7.59%
step 5: MAE=2.1982, RMSE=3.3590, MAPE=7.64%
step 6: MAE=2.2079, RMSE=3.3793, MAPE=7.69%
step 7: MAE=2.2173, RMSE=3.3977, MAPE=7.72%
step 8: MAE=2.2242, RMSE=3.4115, MAPE=7.75%
average: MAE=2.1317, RMSE=3.2362, MAPE=7.40%
total testing time: 17.1s
total time: 19.5min
