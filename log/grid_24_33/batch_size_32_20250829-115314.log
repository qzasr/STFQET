time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=32, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 655,648
**** training model ****
2025-08-29 11:54:22 | epoch: 0001/100, training time: 48.0s, inference time: 1.3s
train loss: 2.8446, val_loss: 2.2874
val loss decrease from inf to 2.2874, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 11:55:11 | epoch: 0002/100, training time: 47.2s, inference time: 1.3s
train loss: 2.3344, val_loss: 2.2184
val loss decrease from 2.2874 to 2.2184, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 11:55:59 | epoch: 0003/100, training time: 47.4s, inference time: 1.3s
train loss: 2.2329, val_loss: 2.1374
val loss decrease from 2.2184 to 2.1374, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 11:56:48 | epoch: 0004/100, training time: 47.7s, inference time: 1.3s
train loss: 2.1651, val_loss: 2.0909
val loss decrease from 2.1374 to 2.0909, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 11:57:37 | epoch: 0005/100, training time: 47.3s, inference time: 1.3s
train loss: 2.1582, val_loss: 2.0926
2025-08-29 11:58:26 | epoch: 0006/100, training time: 47.3s, inference time: 1.3s
train loss: 2.1461, val_loss: 2.0743
val loss decrease from 2.0909 to 2.0743, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 11:59:15 | epoch: 0007/100, training time: 47.8s, inference time: 1.3s
train loss: 2.1053, val_loss: 2.0721
val loss decrease from 2.0743 to 2.0721, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 12:00:03 | epoch: 0008/100, training time: 47.1s, inference time: 1.3s
train loss: 2.0835, val_loss: 2.0651
val loss decrease from 2.0721 to 2.0651, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 12:00:52 | epoch: 0009/100, training time: 47.8s, inference time: 1.3s
train loss: 2.0803, val_loss: 2.0204
val loss decrease from 2.0651 to 2.0204, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 12:01:41 | epoch: 0010/100, training time: 47.1s, inference time: 1.3s
train loss: 2.0657, val_loss: 2.0850
2025-08-29 12:02:29 | epoch: 0011/100, training time: 47.5s, inference time: 1.3s
train loss: 2.0633, val_loss: 2.0379
2025-08-29 12:03:19 | epoch: 0012/100, training time: 48.3s, inference time: 1.3s
train loss: 2.0637, val_loss: 2.0508
2025-08-29 12:04:08 | epoch: 0013/100, training time: 47.8s, inference time: 1.3s
train loss: 2.0163, val_loss: 2.0475
2025-08-29 12:04:58 | epoch: 0014/100, training time: 48.6s, inference time: 1.3s
train loss: 2.0339, val_loss: 2.0178
val loss decrease from 2.0204 to 2.0178, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 12:05:47 | epoch: 0015/100, training time: 47.9s, inference time: 1.3s
train loss: 2.0314, val_loss: 2.0163
val loss decrease from 2.0178 to 2.0163, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 12:06:36 | epoch: 0016/100, training time: 47.2s, inference time: 1.3s
train loss: 2.0124, val_loss: 2.0547
2025-08-29 12:07:25 | epoch: 0017/100, training time: 47.8s, inference time: 1.3s
train loss: 2.0040, val_loss: 2.0474
2025-08-29 12:08:13 | epoch: 0018/100, training time: 47.1s, inference time: 1.3s
train loss: 1.9974, val_loss: 2.0495
2025-08-29 12:09:01 | epoch: 0019/100, training time: 47.2s, inference time: 1.3s
train loss: 2.0033, val_loss: 2.0676
2025-08-29 12:09:50 | epoch: 0020/100, training time: 47.7s, inference time: 1.3s
train loss: 1.9836, val_loss: 2.0586
2025-08-29 12:10:39 | epoch: 0021/100, training time: 47.1s, inference time: 1.3s
train loss: 1.9757, val_loss: 2.0926
2025-08-29 12:11:28 | epoch: 0022/100, training time: 47.7s, inference time: 1.3s
train loss: 1.9614, val_loss: 2.0535
2025-08-29 12:12:17 | epoch: 0023/100, training time: 47.9s, inference time: 1.3s
train loss: 1.9454, val_loss: 2.0413
early stop at epoch: 0023
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.8253, RMSE: 2.8435, MAPE: 6.19%
performance in each prediction step (train)
step 1: MAE=1.5378, RMSE=2.3274, MAPE=5.22%
step 2: MAE=1.8312, RMSE=2.8442, MAPE=6.20%
step 3: MAE=1.8588, RMSE=2.9048, MAPE=6.29%
step 4: MAE=1.8587, RMSE=2.9094, MAPE=6.29%
step 5: MAE=1.8625, RMSE=2.9168, MAPE=6.31%
step 6: MAE=1.8685, RMSE=2.9253, MAPE=6.34%
step 7: MAE=1.8813, RMSE=2.9444, MAPE=6.39%
step 8: MAE=1.9038, RMSE=2.9755, MAPE=6.48%
average: MAE=1.8253, RMSE=2.8435, MAPE=6.19%
val MAE: 2.0422, RMSE: 3.1390, MAPE: 6.95%
performance in each prediction step (val)
step 1: MAE=1.6643, RMSE=2.4782, MAPE=5.65%
step 2: MAE=2.0142, RMSE=3.0523, MAPE=6.84%
step 3: MAE=2.0759, RMSE=3.1830, MAPE=7.06%
step 4: MAE=2.0956, RMSE=3.2371, MAPE=7.13%
step 5: MAE=2.1038, RMSE=3.2575, MAPE=7.16%
step 6: MAE=2.1139, RMSE=3.2769, MAPE=7.20%
step 7: MAE=2.1272, RMSE=3.3024, MAPE=7.24%
step 8: MAE=2.1426, RMSE=3.3243, MAPE=7.29%
average: MAE=2.0422, RMSE=3.1390, MAPE=6.95%
test MAE: 2.0981, RMSE: 3.2350, MAPE: 7.10%
performance in each prediction step (test)
step 1: MAE=1.6842, RMSE=2.4943, MAPE=5.70%
step 2: MAE=2.0613, RMSE=3.1468, MAPE=6.97%
step 3: MAE=2.1316, RMSE=3.2924, MAPE=7.21%
step 4: MAE=2.1588, RMSE=3.3479, MAPE=7.30%
step 5: MAE=2.1741, RMSE=3.3794, MAPE=7.35%
step 6: MAE=2.1806, RMSE=3.3897, MAPE=7.38%
step 7: MAE=2.1904, RMSE=3.4060, MAPE=7.42%
step 8: MAE=2.2036, RMSE=3.4235, MAPE=7.47%
average: MAE=2.0981, RMSE=3.2350, MAPE=7.10%
total testing time: 13.2s
total time: 19.2min
