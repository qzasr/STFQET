time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=24, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 5,491,360
**** training model ****
2025-08-29 04:49:27 | epoch: 0001/100, training time: 125.2s, inference time: 4.2s
train loss: 2.7281, val_loss: 2.2080
val loss decrease from inf to 2.2080, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 04:51:36 | epoch: 0002/100, training time: 125.3s, inference time: 4.2s
train loss: 2.5067, val_loss: 2.1547
val loss decrease from 2.2080 to 2.1547, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 04:53:45 | epoch: 0003/100, training time: 124.7s, inference time: 4.2s
train loss: 2.3686, val_loss: 2.0807
val loss decrease from 2.1547 to 2.0807, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 04:55:55 | epoch: 0004/100, training time: 125.6s, inference time: 4.2s
train loss: 2.3901, val_loss: 2.0922
2025-08-29 04:58:06 | epoch: 0005/100, training time: 126.5s, inference time: 4.2s
train loss: 2.3329, val_loss: 2.0650
val loss decrease from 2.0807 to 2.0650, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 05:00:15 | epoch: 0006/100, training time: 125.1s, inference time: 4.2s
train loss: 2.3043, val_loss: 2.1004
2025-08-29 05:02:25 | epoch: 0007/100, training time: 125.9s, inference time: 4.2s
train loss: 2.3116, val_loss: 2.0378
val loss decrease from 2.0650 to 2.0378, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 05:04:35 | epoch: 0008/100, training time: 126.1s, inference time: 4.2s
train loss: 2.3083, val_loss: 2.1185
2025-08-29 05:06:45 | epoch: 0009/100, training time: 125.8s, inference time: 4.2s
train loss: 2.2596, val_loss: 2.0773
2025-08-29 05:08:55 | epoch: 0010/100, training time: 125.4s, inference time: 4.2s
train loss: 2.2604, val_loss: 2.0825
2025-08-29 05:11:05 | epoch: 0011/100, training time: 126.0s, inference time: 4.2s
train loss: 2.2651, val_loss: 2.0780
2025-08-29 05:13:15 | epoch: 0012/100, training time: 125.4s, inference time: 4.2s
train loss: 2.2381, val_loss: 2.0529
2025-08-29 05:15:28 | epoch: 0013/100, training time: 129.2s, inference time: 4.2s
train loss: 2.2302, val_loss: 2.0290
val loss decrease from 2.0378 to 2.0290, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 05:17:38 | epoch: 0014/100, training time: 125.6s, inference time: 4.2s
train loss: 2.2643, val_loss: 2.1044
2025-08-29 05:19:48 | epoch: 0015/100, training time: 126.2s, inference time: 4.2s
train loss: 2.2123, val_loss: 2.0592
2025-08-29 05:21:57 | epoch: 0016/100, training time: 125.0s, inference time: 4.2s
train loss: 2.2495, val_loss: 2.2742
2025-08-29 05:24:07 | epoch: 0017/100, training time: 125.2s, inference time: 4.2s
train loss: 2.2009, val_loss: 2.0702
2025-08-29 05:26:16 | epoch: 0018/100, training time: 125.0s, inference time: 4.2s
train loss: 2.2046, val_loss: 2.0741
2025-08-29 05:28:26 | epoch: 0019/100, training time: 125.5s, inference time: 4.2s
train loss: 2.1729, val_loss: 2.0507
2025-08-29 05:30:36 | epoch: 0020/100, training time: 126.4s, inference time: 4.2s
train loss: 2.1939, val_loss: 2.1337
2025-08-29 05:32:46 | epoch: 0021/100, training time: 125.6s, inference time: 4.2s
train loss: 2.1498, val_loss: 2.0600
early stop at epoch: 0021
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.7813, RMSE: 2.7630, MAPE: 6.02%
performance in each prediction step (train)
step 1: MAE=1.5068, RMSE=2.2835, MAPE=5.07%
step 2: MAE=1.7840, RMSE=2.7618, MAPE=6.00%
step 3: MAE=1.7988, RMSE=2.7972, MAPE=6.07%
step 4: MAE=1.7994, RMSE=2.7985, MAPE=6.07%
step 5: MAE=1.8083, RMSE=2.8116, MAPE=6.10%
step 6: MAE=1.8250, RMSE=2.8407, MAPE=6.17%
step 7: MAE=1.8452, RMSE=2.8773, MAPE=6.25%
step 8: MAE=1.8827, RMSE=2.9334, MAPE=6.39%
average: MAE=1.7813, RMSE=2.7630, MAPE=6.02%
val MAE: 2.0620, RMSE: 3.1781, MAPE: 7.01%
performance in each prediction step (val)
step 1: MAE=1.6637, RMSE=2.4874, MAPE=5.60%
step 2: MAE=2.0342, RMSE=3.1000, MAPE=6.89%
step 3: MAE=2.0989, RMSE=3.2432, MAPE=7.14%
step 4: MAE=2.1182, RMSE=3.2860, MAPE=7.21%
step 5: MAE=2.1323, RMSE=3.3084, MAPE=7.26%
step 6: MAE=2.1411, RMSE=3.3219, MAPE=7.30%
step 7: MAE=2.1468, RMSE=3.3293, MAPE=7.32%
step 8: MAE=2.1608, RMSE=3.3485, MAPE=7.37%
average: MAE=2.0620, RMSE=3.1781, MAPE=7.01%
test MAE: 2.1035, RMSE: 3.2451, MAPE: 7.17%
performance in each prediction step (test)
step 1: MAE=1.6789, RMSE=2.4933, MAPE=5.67%
step 2: MAE=2.0666, RMSE=3.1639, MAPE=7.01%
step 3: MAE=2.1376, RMSE=3.3069, MAPE=7.28%
step 4: MAE=2.1599, RMSE=3.3504, MAPE=7.36%
step 5: MAE=2.1781, RMSE=3.3833, MAPE=7.43%
step 6: MAE=2.1928, RMSE=3.4050, MAPE=7.49%
step 7: MAE=2.2011, RMSE=3.4210, MAPE=7.53%
step 8: MAE=2.2130, RMSE=3.4368, MAPE=7.57%
average: MAE=2.1035, RMSE=3.2451, MAPE=7.17%
total testing time: 42.8s
total time: 46.5min
