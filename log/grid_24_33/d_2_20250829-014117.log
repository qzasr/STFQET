time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=2, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.003, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 67,216
**** training model ****
2025-08-29 01:42:49 | epoch: 0001/100, training time: 71.3s, inference time: 2.1s
train loss: 3.1664, val_loss: 2.4055
val loss decrease from inf to 2.4055, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 01:44:03 | epoch: 0002/100, training time: 72.0s, inference time: 2.1s
train loss: 2.7038, val_loss: 2.2477
val loss decrease from 2.4055 to 2.2477, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 01:45:23 | epoch: 0003/100, training time: 77.9s, inference time: 2.2s
train loss: 2.6110, val_loss: 2.2160
val loss decrease from 2.2477 to 2.2160, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 01:46:41 | epoch: 0004/100, training time: 75.1s, inference time: 2.3s
train loss: 2.5296, val_loss: 2.1771
val loss decrease from 2.2160 to 2.1771, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 01:47:58 | epoch: 0005/100, training time: 75.3s, inference time: 2.1s
train loss: 2.5188, val_loss: 2.1489
val loss decrease from 2.1771 to 2.1489, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 01:49:11 | epoch: 0006/100, training time: 70.7s, inference time: 2.1s
train loss: 2.4997, val_loss: 2.1344
val loss decrease from 2.1489 to 2.1344, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 01:50:24 | epoch: 0007/100, training time: 70.6s, inference time: 2.2s
train loss: 2.4794, val_loss: 2.1528
2025-08-29 01:51:38 | epoch: 0008/100, training time: 72.6s, inference time: 2.1s
train loss: 2.4519, val_loss: 2.1398
2025-08-29 01:52:51 | epoch: 0009/100, training time: 70.8s, inference time: 2.1s
train loss: 2.4389, val_loss: 2.1502
2025-08-29 01:54:04 | epoch: 0010/100, training time: 70.9s, inference time: 2.1s
train loss: 2.4464, val_loss: 2.1438
2025-08-29 01:55:15 | epoch: 0011/100, training time: 68.2s, inference time: 2.1s
train loss: 2.4255, val_loss: 2.0989
val loss decrease from 2.1344 to 2.0989, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 01:56:23 | epoch: 0012/100, training time: 66.3s, inference time: 2.0s
train loss: 2.4603, val_loss: 2.1060
2025-08-29 01:57:32 | epoch: 0013/100, training time: 67.1s, inference time: 2.1s
train loss: 2.4253, val_loss: 2.0996
2025-08-29 01:58:47 | epoch: 0014/100, training time: 72.7s, inference time: 2.1s
train loss: 2.4206, val_loss: 2.1642
2025-08-29 01:59:56 | epoch: 0015/100, training time: 67.4s, inference time: 2.0s
train loss: 2.4334, val_loss: 2.0892
val loss decrease from 2.0989 to 2.0892, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 02:01:05 | epoch: 0016/100, training time: 66.5s, inference time: 2.1s
train loss: 2.4125, val_loss: 2.1360
2025-08-29 02:02:19 | epoch: 0017/100, training time: 71.6s, inference time: 2.2s
train loss: 2.4165, val_loss: 2.0836
val loss decrease from 2.0892 to 2.0836, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 02:03:27 | epoch: 0018/100, training time: 66.7s, inference time: 2.0s
train loss: 2.4440, val_loss: 2.0890
2025-08-29 02:04:36 | epoch: 0019/100, training time: 66.1s, inference time: 2.0s
train loss: 2.3850, val_loss: 2.0676
val loss decrease from 2.0836 to 2.0676, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 02:05:44 | epoch: 0020/100, training time: 66.8s, inference time: 2.1s
train loss: 2.4124, val_loss: 2.0840
2025-08-29 02:06:57 | epoch: 0021/100, training time: 70.5s, inference time: 2.1s
train loss: 2.4029, val_loss: 2.1018
2025-08-29 02:08:08 | epoch: 0022/100, training time: 69.3s, inference time: 2.1s
train loss: 2.4115, val_loss: 2.0981
2025-08-29 02:09:20 | epoch: 0023/100, training time: 69.3s, inference time: 2.1s
train loss: 2.4034, val_loss: 2.0828
2025-08-29 02:10:29 | epoch: 0024/100, training time: 67.6s, inference time: 2.1s
train loss: 2.3895, val_loss: 2.1105
2025-08-29 02:11:44 | epoch: 0025/100, training time: 72.6s, inference time: 2.1s
train loss: 2.3951, val_loss: 2.0684
2025-08-29 02:13:00 | epoch: 0026/100, training time: 73.9s, inference time: 2.1s
train loss: 2.4116, val_loss: 2.0879
2025-08-29 02:14:10 | epoch: 0027/100, training time: 67.8s, inference time: 2.1s
train loss: 2.4052, val_loss: 2.0802
early stop at epoch: 0027
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 2.0067, RMSE: 3.0734, MAPE: 6.92%
performance in each prediction step (train)
step 1: MAE=1.6671, RMSE=2.4779, MAPE=5.77%
step 2: MAE=1.9876, RMSE=3.0197, MAPE=6.82%
step 3: MAE=2.0411, RMSE=3.1272, MAPE=7.02%
step 4: MAE=2.0499, RMSE=3.1528, MAPE=7.06%
step 5: MAE=2.0583, RMSE=3.1711, MAPE=7.08%
step 6: MAE=2.0664, RMSE=3.1891, MAPE=7.12%
step 7: MAE=2.0795, RMSE=3.2085, MAPE=7.18%
step 8: MAE=2.1041, RMSE=3.2412, MAPE=7.30%
average: MAE=2.0067, RMSE=3.0734, MAPE=6.92%
val MAE: 2.0805, RMSE: 3.1502, MAPE: 7.08%
performance in each prediction step (val)
step 1: MAE=1.7231, RMSE=2.5258, MAPE=5.88%
step 2: MAE=2.0587, RMSE=3.0866, MAPE=7.00%
step 3: MAE=2.1156, RMSE=3.1972, MAPE=7.21%
step 4: MAE=2.1255, RMSE=3.2352, MAPE=7.24%
step 5: MAE=2.1357, RMSE=3.2558, MAPE=7.26%
step 6: MAE=2.1461, RMSE=3.2789, MAPE=7.29%
step 7: MAE=2.1604, RMSE=3.2990, MAPE=7.34%
step 8: MAE=2.1790, RMSE=3.3234, MAPE=7.42%
average: MAE=2.0805, RMSE=3.1502, MAPE=7.08%
test MAE: 2.1138, RMSE: 3.2175, MAPE: 7.22%
performance in each prediction step (test)
step 1: MAE=1.7266, RMSE=2.5261, MAPE=5.94%
step 2: MAE=2.0702, RMSE=3.1080, MAPE=7.06%
step 3: MAE=2.1386, RMSE=3.2536, MAPE=7.30%
step 4: MAE=2.1585, RMSE=3.3049, MAPE=7.36%
step 5: MAE=2.1810, RMSE=3.3471, MAPE=7.42%
step 6: MAE=2.1944, RMSE=3.3752, MAPE=7.48%
step 7: MAE=2.2123, RMSE=3.4049, MAPE=7.55%
step 8: MAE=2.2285, RMSE=3.4199, MAPE=7.63%
average: MAE=2.1138, RMSE=3.2175, MAPE=7.22%
total testing time: 21.9s
total time: 33.2min
