time_slot=15, torch_seed=46, num_link=223, num_his=8, num_pred=8, L=2, K=8, d=8, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2, batch_size=8, max_epoch=100, patience=8, learning_rate=0.0005, decay_epoch=20, traffic_file='./data/Traffic_speed_(24, 33).csv', query_file='./data/query_beijing_0201_grid_start_destination_count.npz', SE_file='./data/Gf_grid_24_33_id.txt', adj_file='./data/edge_list_grid_(24,33)_weight.txt', row=24, col=33, model_file='./save_model/grid_24_33/Model_GF_test.pkl', log_file='./log/grid_24_33/log_test', STE_SE_FC_bn_decay=0.1, STE_SE_FC_drop=0.07, STE_SE_FC_act1='relu', STE_SE_FC_act2='none', STE_TE_FC_bn_decay=0.1, STE_TE_FC_drop=0.01, STE_TE_FC_act1='relu', STE_TE_FC_act2='none', FFT_FC_bn_decay=0.05, FFT_FC_drop=0.01, FFT_FC_act1='relu', FFT_FC_act2='none', KNA_W_bn_decay=0.1, KNA_W_drop=0.01, KNA_W_act1='relu', KNA_W_act2='none', KNA_Wq_bn_decay=0.1, KNA_Wq_drop=0.01, KNA_Wq_act='none', KNA_Wk_bn_decay=0.1, KNA_Wk_drop=0.01, KNA_Wk_act='none', KNA_Wv_bn_decay=0.1, KNA_Wv_drop=0.01, KNA_Wv_act='none', KNA_Fusion_bn_decay=0.1, KNA_Fusion_drop=0.01, KNA_Fusion_act='relu', SA_FCq_bn_decay=0.1, SA_FCq_drop=0.01, SA_FCq_act='relu', SA_FCk_bn_decay=0.1, SA_FCk_drop=0.01, SA_FCk_act='relu', SA_FCv_bn_decay=0.1, SA_FCv_drop=0.01, SA_FCv_act='relu', SA_FC_bn_decay=0.1, SA_FC_drop=0.01, SA_FC_act='relu', TA_Wq_bn_decay=0.1, TA_Wq_drop=0.01, TA_Wq_act='none', TA_Wk_bn_decay=0.1, TA_Wk_drop=0.01, TA_Wk_act='none', TA_Wv_bn_decay=0.1, TA_Wv_drop=0.01, TA_Wv_act='none', TA_Fusion_bn_decay=0.1, TA_Fusion_drop=0.01, TA_Fusion_act='relu', NAV_Wq_bn_decay=0.1, NAV_Wq_drop=0.01, NAV_Wq_act='none', NAV_Wk_bn_decay=0.1, NAV_Wk_drop=0.01, NAV_Wk_act='none', NAV_Wv_bn_decay=0.1, NAV_Wv_drop=0.01, NAV_Wv_act='none', NAV_Mapping_bn_decay=0.1, NAV_Mapping_drop=0.01, NAV_Mapping_act='relu', NAV_Fusion_bn_decay=0.1, NAV_Fusion_drop=0.01, NAV_Fusion_act='relu', STB_SpatialFusion_bn_decay=0.1, STB_SpatialFusion_drop=0.01, STB_SpatialFusion_act='relu', STB_TemporalFusion_bn_decay=0.1, STB_TemporalFusion_drop=0.01, STB_TemporalFusion_act='relu', STB_FinalFusion_bn_decay=0.1, STB_FinalFusion_drop=0.01, STB_FinalFusion_act='relu', STB_Gate_bn_decay=0.1, STB_Gate_drop=0.01, STB_Gate_act1='relu', STB_Gate_act2='sigmoid', TA_FCq_bn_decay=0.1, TA_FCq_drop=0.01, TA_FCq_act='relu', TA_FCk_bn_decay=0.1, TA_FCk_drop=0.01, TA_FCk_act='relu', TA_FCv_bn_decay=0.1, TA_FCv_drop=0.01, TA_FCv_act='relu', TA_FC_bn_decay=0.1, TA_FC_drop=0.01, TA_FC_act='relu', Traffic_Linear_bn_decay=0.1, Traffic_Linear_drop=0.01, Traffic_Linear_act1='relu', Traffic_Linear_act2='none', Query_Linear_bn_decay=0.1, Query_Linear_drop=0.01, Query_Linear_act1='relu', Query_Linear_act2='none', Output_bn_decay=0.1, Output_drop=0.01, Output_act1='relu', Output_act2='none', GDC_bn_decay=0.1, TSP_bn_decay=0.1
Using device: cuda:0
trainX: torch.Size([4084, 8, 223])		 trainY: torch.Size([4084, 8, 223])
valX:   torch.Size([571, 8, 223])		valY:   torch.Size([571, 8, 223])
testX:   torch.Size([1156, 8, 223])		testY:   torch.Size([1156, 8, 223])
mean:   31.8979		std:   10.7164
data loaded!
compiling model...
trainable parameters: 655,648
**** training model ****
2025-08-29 18:37:10 | epoch: 0001/100, training time: 66.2s, inference time: 2.1s
train loss: 3.0806, val_loss: 2.8324
val loss decrease from inf to 2.8324, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:38:17 | epoch: 0002/100, training time: 64.9s, inference time: 2.1s
train loss: 2.6248, val_loss: 2.4593
val loss decrease from 2.8324 to 2.4593, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:39:28 | epoch: 0003/100, training time: 69.3s, inference time: 2.1s
train loss: 2.5237, val_loss: 2.2884
val loss decrease from 2.4593 to 2.2884, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:40:35 | epoch: 0004/100, training time: 65.2s, inference time: 2.0s
train loss: 2.4706, val_loss: 2.2492
val loss decrease from 2.2884 to 2.2492, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:41:43 | epoch: 0005/100, training time: 65.9s, inference time: 2.1s
train loss: 2.4442, val_loss: 2.1474
val loss decrease from 2.2492 to 2.1474, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:42:51 | epoch: 0006/100, training time: 65.7s, inference time: 2.1s
train loss: 2.4120, val_loss: 2.1435
val loss decrease from 2.1474 to 2.1435, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:43:59 | epoch: 0007/100, training time: 65.8s, inference time: 2.1s
train loss: 2.4041, val_loss: 2.1206
val loss decrease from 2.1435 to 2.1206, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:45:07 | epoch: 0008/100, training time: 65.8s, inference time: 2.1s
train loss: 2.3896, val_loss: 2.0889
val loss decrease from 2.1206 to 2.0889, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:46:14 | epoch: 0009/100, training time: 65.6s, inference time: 2.1s
train loss: 2.3689, val_loss: 2.0904
2025-08-29 18:47:28 | epoch: 0010/100, training time: 71.8s, inference time: 2.1s
train loss: 2.3598, val_loss: 2.1808
2025-08-29 18:48:38 | epoch: 0011/100, training time: 67.0s, inference time: 2.1s
train loss: 2.3394, val_loss: 2.0961
2025-08-29 18:49:55 | epoch: 0012/100, training time: 75.3s, inference time: 2.1s
train loss: 2.3399, val_loss: 2.0845
val loss decrease from 2.0889 to 2.0845, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:51:10 | epoch: 0013/100, training time: 73.3s, inference time: 2.2s
train loss: 2.2863, val_loss: 2.0812
val loss decrease from 2.0845 to 2.0812, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:52:19 | epoch: 0014/100, training time: 66.4s, inference time: 2.1s
train loss: 2.2779, val_loss: 2.0536
val loss decrease from 2.0812 to 2.0536, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:53:28 | epoch: 0015/100, training time: 66.5s, inference time: 2.1s
train loss: 2.3052, val_loss: 2.0815
2025-08-29 18:54:37 | epoch: 0016/100, training time: 67.2s, inference time: 2.1s
train loss: 2.2865, val_loss: 2.0691
2025-08-29 18:55:45 | epoch: 0017/100, training time: 66.1s, inference time: 2.1s
train loss: 2.2779, val_loss: 2.0750
2025-08-29 18:56:53 | epoch: 0018/100, training time: 66.2s, inference time: 2.1s
train loss: 2.2568, val_loss: 2.0201
val loss decrease from 2.0536 to 2.0201, saving model to ./save_model/grid_24_33/Model_GF_test.pkl
2025-08-29 18:58:01 | epoch: 0019/100, training time: 66.0s, inference time: 2.1s
train loss: 2.2735, val_loss: 2.1459
2025-08-29 18:59:10 | epoch: 0020/100, training time: 66.7s, inference time: 2.1s
train loss: 2.2594, val_loss: 2.0898
2025-08-29 19:00:20 | epoch: 0021/100, training time: 67.7s, inference time: 2.1s
train loss: 2.2397, val_loss: 2.0454
2025-08-29 19:01:40 | epoch: 0022/100, training time: 77.8s, inference time: 2.1s
train loss: 2.2476, val_loss: 2.0633
2025-08-29 19:02:58 | epoch: 0023/100, training time: 76.0s, inference time: 2.1s
train loss: 2.2527, val_loss: 2.0575
2025-08-29 19:04:16 | epoch: 0024/100, training time: 76.1s, inference time: 2.1s
train loss: 2.2551, val_loss: 2.0459
2025-08-29 19:05:29 | epoch: 0025/100, training time: 71.2s, inference time: 2.1s
train loss: 2.2455, val_loss: 2.0852
2025-08-29 19:06:47 | epoch: 0026/100, training time: 75.8s, inference time: 2.1s
train loss: 2.2371, val_loss: 2.0371
early stop at epoch: 0026
Training completed. Best model saved to ./save_model/grid_24_33/Model_GF_test.pkl
**** testing model ****
loading model from ./save_model/grid_24_33/Model_GF_test.pkl
model loaded!
evaluating...
train MAE: 1.8699, RMSE: 2.9083, MAPE: 6.38%
performance in each prediction step (train)
step 1: MAE=1.5655, RMSE=2.3584, MAPE=5.33%
step 2: MAE=1.8733, RMSE=2.8971, MAPE=6.37%
step 3: MAE=1.9051, RMSE=2.9717, MAPE=6.49%
step 4: MAE=1.9061, RMSE=2.9818, MAPE=6.50%
step 5: MAE=1.9081, RMSE=2.9855, MAPE=6.52%
step 6: MAE=1.9146, RMSE=2.9960, MAPE=6.54%
step 7: MAE=1.9298, RMSE=3.0193, MAPE=6.60%
step 8: MAE=1.9563, RMSE=3.0570, MAPE=6.70%
average: MAE=1.8699, RMSE=2.9083, MAPE=6.38%
val MAE: 2.0388, RMSE: 3.1774, MAPE: 7.00%
performance in each prediction step (val)
step 1: MAE=1.6670, RMSE=2.4896, MAPE=5.68%
step 2: MAE=2.0256, RMSE=3.1192, MAPE=6.93%
step 3: MAE=2.0799, RMSE=3.2419, MAPE=7.14%
step 4: MAE=2.0911, RMSE=3.2785, MAPE=7.19%
step 5: MAE=2.1000, RMSE=3.3032, MAPE=7.23%
step 6: MAE=2.1072, RMSE=3.3204, MAPE=7.24%
step 7: MAE=2.1148, RMSE=3.3303, MAPE=7.26%
step 8: MAE=2.1247, RMSE=3.3364, MAPE=7.29%
average: MAE=2.0388, RMSE=3.1774, MAPE=7.00%
test MAE: 2.0672, RMSE: 3.1997, MAPE: 7.08%
performance in each prediction step (test)
step 1: MAE=1.6691, RMSE=2.4707, MAPE=5.68%
step 2: MAE=2.0369, RMSE=3.1201, MAPE=6.95%
step 3: MAE=2.1010, RMSE=3.2628, MAPE=7.19%
step 4: MAE=2.1235, RMSE=3.3138, MAPE=7.28%
step 5: MAE=2.1366, RMSE=3.3386, MAPE=7.33%
step 6: MAE=2.1460, RMSE=3.3523, MAPE=7.36%
step 7: MAE=2.1561, RMSE=3.3641, MAPE=7.39%
step 8: MAE=2.1681, RMSE=3.3753, MAPE=7.44%
average: MAE=2.0672, RMSE=3.1997, MAPE=7.08%
total testing time: 21.3s
total time: 31.4min
